{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introductory-apple",
   "metadata": {},
   "source": [
    "## Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "median-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "from importlib import import_module\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "corporate-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n",
    "    \n",
    "    Args:\n",
    "        seed: seed 정수값\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-lodging",
   "metadata": {},
   "source": [
    "## Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intermediate-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- parameters\n",
    "img_root = '/opt/ml/input/data/train/images'  # 학습 이미지 폴더의 경로\n",
    "label_path = '/opt/ml/input/data/train/train.csv'  # 학습 메타파일의 경로\n",
    "\n",
    "model_name = \"resnet50\"  # 모델 이름\n",
    "use_pretrained = True  # pretrained-model의 사용 여부\n",
    "freeze_backbone = False  # classifier head 이 외 부분을 업데이트되지 않게 할 것인지 여부\n",
    "\n",
    "##[not yet] 변화 시켜보기\n",
    "val_split = 0.4  # validation dataset의 비율\n",
    "batch_size = 64 # 2-> 64\n",
    "num_workers = 0 # 0-> 4로 change\n",
    "num_classes = 18\n",
    "\n",
    "num_epochs = 10  # 학습할 epoch의 수 5->10\n",
    "lr = 1e-4\n",
    "lr_decay_step = 10\n",
    "\n",
    "train_log_interval = 20  # logging할 iteration의 주기\n",
    "name = \"res11_resnet50_base_aug_default_batch64_f1loss\"  # 결과를 저장하는 폴더의 이름\n",
    "\n",
    "# -- settings\n",
    "use_cuda = torch.cuda.is_available()|\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-projector",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "#### 사용해볼 loss Function\n",
    "#### --> Cross Entropy Loss, Focal Loss, Label Smoothing, F1 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-description",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excess-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cross Entropy Loss\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-cover",
   "metadata": {},
   "source": [
    "## Creterion 정의!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "constitutional-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creterion 정의\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-salon",
   "metadata": {},
   "source": [
    "## Model(Pretrained) && Optimizer 정의 \n",
    "#### pytorch 기본 제공 pretrained 모델은 여기 참조 https://pytorch.org/vision/stable/models.html \n",
    "### efficient net github 주소 :: https://github.com/lukemelas/EfficientNet-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-denver",
   "metadata": {},
   "source": [
    "### ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "educated-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# -- model\\nmodel_cls = getattr(import_module(\"model\"), model_name)\\nprint(model_cls)\\nmodel = model_cls(\\n    num_classes=num_classes,\\n    pretrained=use_pretrained,\\n    freeze=freeze_backbone\\n).to(device)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pretrained model 이용\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "'''\n",
    "# -- model\n",
    "model_cls = getattr(import_module(\"model\"), model_name)\n",
    "print(model_cls)\n",
    "model = model_cls(\n",
    "    num_classes=num_classes,\n",
    "    pretrained=use_pretrained,\n",
    "    freeze=freeze_backbone\n",
    ").to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-family",
   "metadata": {},
   "source": [
    "### EfficientNet-b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innocent-retail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b7').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-collection",
   "metadata": {},
   "source": [
    "### EfficientNet-b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pressed-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b4').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-leeds",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "breathing-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supposed-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SGD optimizer\n",
    "optimizer = SGD(model.parameters(), lr=lr, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "chemical-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(model.named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-verification",
   "metadata": {},
   "source": [
    "## Scheduler\n",
    "* Scheduler은 optimizer의 learning rate를 동적으로 변경시키는 기능을 합니다.\n",
    "* Optimizer과 Scheduler를 적절히 활용하면 모델이 좋은 성능으로 Fitting하는데 도움을 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "seeing-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- scheduler: StepLR\n",
    "# 지정된 step마다 learning rate를 감소시킵니다.\n",
    "scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "three-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- scheduler: ReduceLROnPlateau\n",
    "# 성능이 향상되지 않을 때 learning rate를 줄입니다. patience=10은 10회 동안 성능 향상이 없을 경우입니다.\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "measured-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- scheduler: CosineAnnealingLR\n",
    "# CosineAnnealing은 learning rate를 cosine 그래프처럼 변화시킵니다.\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-dodge",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-portable",
   "metadata": {},
   "source": [
    "### dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "greek-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- dataset\n",
    "dataset_module = getattr(import_module(\"dataset\"), 'MaskBaseDataset')\n",
    "dataset = dataset_module(\n",
    "    data_dir=img_root,\n",
    ")\n",
    "num_classes = dataset.num_classes  # 18\n",
    "\n",
    "# -- augmentation\n",
    "transform_module = getattr(import_module(\"dataset\"), 'BaseAugmentation') #Base -> CustomAugmentation -> 취소\n",
    "transform = transform_module(\n",
    "    resize=[128, 96],\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "\n",
    "# -- data_loader\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-wedding",
   "metadata": {},
   "source": [
    "### Callback - Checkpoint, Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "corrected-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Callback1: Checkpoint - Accuracy가 높아질 때마다 모델을 저장합니다.\n",
    "# 학습 코드에서 이어집니다.\n",
    "\n",
    "# -- Callback2: Early Stopping - 성능이 일정 기간동안 향상이 없을 경우 학습을 종료합니다.\n",
    "patience = 10\n",
    "counter = 0\n",
    "# 학습 코드에서 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-hobby",
   "metadata": {},
   "source": [
    "### Training Method - Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "institutional-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient Accumulation\n",
    "accumulation_steps = 2\n",
    "# 학습코드에서 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-direction",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "altered-partnership",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be smaller than num_classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ff010ebeb4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-fc5d5fa80e0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be smaller than num_classes."
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n",
    "\n",
    "counter = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # -- Gradient Accumulation\n",
    "        if (idx+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            train_acc = matches / batch_size / train_log_interval\n",
    "            current_lr = scheduler.get_last_lr()\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_set)\n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "genetic-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/code\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-edward",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attractive-spending",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataset.TestDataset object at 0x7fcf5842f850>\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "test_img_root = '/opt/ml/input/data/eval/'  # 학습 이미지 폴더의 경로\n",
    "# public, private 테스트셋이 존재하니 각각의 예측결과를 저장합니다.\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_img_root, 'info.csv'))\n",
    "image_dir = os.path.join(test_img_root, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "resize = (96, 128)\n",
    "'''\n",
    "transform = transforms.Compose([\n",
    "    Resize((96, 128), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "])\n",
    "test_dataset = TestDataset(test_img_root, transform)\n",
    "'''\n",
    "test_dataset = TestDataset(image_paths, resize)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "print(test_loader.dataset)\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in test_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_img_root, 'submission.csv'), index=False)\n",
    "print('test inference is done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-price",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
